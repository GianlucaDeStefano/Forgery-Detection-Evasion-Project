{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from Datasets.CASIA2 import CASIA2\n",
    "from Datasets.Utilities.Maps.Noiseprint.noiseprint import normalize_noiseprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Download and prepare the dataset\n",
    "#This will take a while since we have to process each image singularly to extract the noise features\n",
    "from Geneartors.CASIA2.Casia2Generator import Casia2Generator\n",
    "from Models.Customs.BaseClassifier import BaseClassifier\n",
    "#from Models.Customs.ClassifierType1 import ClassifierType1\n",
    "from Utilities.Plots import plot_model_data\n",
    "dataset = CASIA2()\n",
    "dataset.download_and_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown split \"train\". Should be one of ['test_compressed'].",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-101cefe66eba>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain_split\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"train\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mn_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mnsamples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py\u001B[0m in \u001B[0;36mas_dataset\u001B[0;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised)\u001B[0m\n\u001B[1;32m    591\u001B[0m         \u001B[0mas_supervised\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mas_supervised\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    592\u001B[0m     )\n\u001B[0;32m--> 593\u001B[0;31m     \u001B[0mdatasets\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_nested\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbuild_single_dataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msplit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_tuple\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    594\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow_datasets/core/utils/py_utils.py\u001B[0m in \u001B[0;36mmap_nested\u001B[0;34m(function, data_struct, dict_only, map_tuple)\u001B[0m\n\u001B[1;32m    182\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmapped\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    183\u001B[0m   \u001B[0;31m# Singleton\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 184\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_struct\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    185\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py\u001B[0m in \u001B[0;36m_build_single_dataset\u001B[0;34m(self, split, shuffle_files, batch_size, decoders, read_config, as_supervised)\u001B[0m\n\u001B[1;32m    609\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    610\u001B[0m     \u001B[0;31m# Build base dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 611\u001B[0;31m     ds = self._as_dataset(\n\u001B[0m\u001B[1;32m    612\u001B[0m         \u001B[0msplit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    613\u001B[0m         \u001B[0mshuffle_files\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshuffle_files\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py\u001B[0m in \u001B[0;36m_as_dataset\u001B[0;34m(self, split, decoders, read_config, shuffle_files)\u001B[0m\n\u001B[1;32m    966\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode_example\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecoders\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdecoders\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    967\u001B[0m     )\n\u001B[0;32m--> 968\u001B[0;31m     return self._tfrecords_reader.read(\n\u001B[0m\u001B[1;32m    969\u001B[0m         \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    970\u001B[0m         \u001B[0minstructions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow_datasets/core/tfrecords_reader.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, name, instructions, split_infos, read_config, shuffle_files, decode_fn)\u001B[0m\n\u001B[1;32m    360\u001B[0m       )\n\u001B[1;32m    361\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 362\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_read_instruction_to_ds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minstructions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    363\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    364\u001B[0m   def read_files(\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001B[0m in \u001B[0;36mmap_structure\u001B[0;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[1;32m    657\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    658\u001B[0m   return pack_sequence_as(\n\u001B[0;32m--> 659\u001B[0;31m       \u001B[0mstructure\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    660\u001B[0m       expand_composites=expand_composites)\n\u001B[1;32m    661\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    657\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    658\u001B[0m   return pack_sequence_as(\n\u001B[0;32m--> 659\u001B[0;31m       \u001B[0mstructure\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    660\u001B[0m       expand_composites=expand_composites)\n\u001B[1;32m    661\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow_datasets/core/tfrecords_reader.py\u001B[0m in \u001B[0;36m_read_instruction_to_ds\u001B[0;34m(instruction)\u001B[0m\n\u001B[1;32m    351\u001B[0m     \"\"\"\n\u001B[1;32m    352\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_read_instruction_to_ds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minstruction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 353\u001B[0;31m       file_instructions = make_file_instructions(\n\u001B[0m\u001B[1;32m    354\u001B[0m           name, split_infos, instruction, file_format=self._file_format)\n\u001B[1;32m    355\u001B[0m       return self.read_files(\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow_datasets/core/tfrecords_reader.py\u001B[0m in \u001B[0;36mmake_file_instructions\u001B[0;34m(name, split_infos, instruction, file_format)\u001B[0m\n\u001B[1;32m    163\u001B[0m     \u001B[0minstruction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mReadInstruction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_spec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minstruction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    164\u001B[0m   \u001B[0;31m# Create the absolute instruction (per split)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 165\u001B[0;31m   \u001B[0mabsolute_instructions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minstruction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_absolute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname2len\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    166\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m   return _make_file_instructions_from_absolutes(\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow_datasets/core/tfrecords_reader.py\u001B[0m in \u001B[0;36mto_absolute\u001B[0;34m(self, name2len)\u001B[0m\n\u001B[1;32m    665\u001B[0m       \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0m_AbsoluteInstruction\u001B[0m \u001B[0minstances\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mcorresponds\u001B[0m \u001B[0mto\u001B[0m \u001B[0mthe\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mspec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    666\u001B[0m     \"\"\"\n\u001B[0;32m--> 667\u001B[0;31m     return [_rel_to_abs_instr(rel_instr, name2len)\n\u001B[0m\u001B[1;32m    668\u001B[0m             for rel_instr in self._relative_instructions]\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow_datasets/core/tfrecords_reader.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    665\u001B[0m       \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0m_AbsoluteInstruction\u001B[0m \u001B[0minstances\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mcorresponds\u001B[0m \u001B[0mto\u001B[0m \u001B[0mthe\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mspec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    666\u001B[0m     \"\"\"\n\u001B[0;32m--> 667\u001B[0;31m     return [_rel_to_abs_instr(rel_instr, name2len)\n\u001B[0m\u001B[1;32m    668\u001B[0m             for rel_instr in self._relative_instructions]\n",
      "\u001B[0;32m~/anaconda3/envs/mlproject/lib/python3.8/site-packages/tensorflow_datasets/core/tfrecords_reader.py\u001B[0m in \u001B[0;36m_rel_to_abs_instr\u001B[0;34m(rel_instr, name2len)\u001B[0m\n\u001B[1;32m    492\u001B[0m   \u001B[0msplit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrel_instr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplitname\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    493\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0msplit\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mname2len\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 494\u001B[0;31m     raise ValueError('Unknown split \"{}\". Should be one of {}.'.format(\n\u001B[0m\u001B[1;32m    495\u001B[0m         split, list(name2len)))\n\u001B[1;32m    496\u001B[0m   \u001B[0mnum_examples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mname2len\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Unknown split \"train\". Should be one of ['test_compressed']."
     ]
    }
   ],
   "source": [
    "train_split = dataset.as_dataset(split=\"train\")\n",
    "\n",
    "n_cols = 3\n",
    "\n",
    "nsamples = 5\n",
    "\n",
    "samples = train_split.take(nsamples)\n",
    "\n",
    "col_titles = ['Image','Noiseprint','SRM'] \n",
    "\n",
    "nrows = nsamples\n",
    "ncols = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows,ncols,figsize=(12,18))  # create the figure with subplots\n",
    "[ax.set_axis_off() for ax in axes.ravel()]  # remove the axis\n",
    "\n",
    "for ax, col in zip(axes[0], col_titles): # set up the title for each column\n",
    "    ax.set_title(col,fontdict={'fontsize':18,'color':'b'})\n",
    "\n",
    "i = 0\n",
    "for sample in samples:\n",
    "    axes[i,0].imshow(sample[\"image\"])\n",
    "    axes[i,1].imshow(normalize_noiseprint(sample[\"noiseprint\"].numpy()))\n",
    "    axes[i,2].imshow(sample[\"SRM\"])   \n",
    "    i = i + 1 \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Define parameters essentials for the training of the models\n",
    "\n",
    "#Define input parameters\n",
    "input_shape_rgb = (256, 384, 3)\n",
    "input_shape_rbf = (256, 384, 3)\n",
    "input_shape_noiseprint = (256, 384, 1)\n",
    "\n",
    "#We just have to distinguish between tampered and pristine images\n",
    "#and a single class is enough for that\n",
    "output_classes = 1\n",
    "\n",
    "#Define the loss the models will use\n",
    "loss_function = \"binary_crossentropy\"\n",
    "\n",
    "#Define the number of epochs each model has to be trained for\n",
    "epochs = 1\n",
    "\n",
    "#define the size of each training batch\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Define additional parameters not essentials for the training\n",
    "\n",
    "#Set the path to the Log folder in which the logs, the checkpoints and other usefull\n",
    "#data will be used\n",
    "logs_folder = Path(\"../Logs\")\n",
    "\n",
    "#Set verbose = True if you want an extensive printing of logs during the training\n",
    "# and testing of the models\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 generator of datas that has that provide samples with the following structure:\n",
    "#   X -> [RGB image]\n",
    "#   Y -> class of the image\n",
    "# The first generator will produce training data, the second will produce validation data\n",
    "\n",
    "generator_training_rgb = Casia2Generator(dataset.as_dataset(split=\"train\"),[\"rgb\"],batch_size)\n",
    "generator_validation_rgb = Casia2Generator(dataset.as_dataset(split=\"validation\"),[\"rgb\"],batch_size)\n",
    "#Train a Resnet Classifier using the RGB data\n",
    "model_rgb = BaseClassifier(input_shape_rgb,output_classes,\"RGB model\",logs_folder,verbose)\n",
    "history_rgb , rgb_model_path, rgb_checkpoint_path = model_rgb.train_model(generator_training_rgb,generator_validation_rgb,epochs,loss_function,save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_model_data(history_rgb,(\"accuracy\",\"val_accuracy\"),(\"training  accuracy\",\"validation accuracy\"),\"Rgb model training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 generator of datas that has that provide samples with the following structure:\n",
    "#   X -> [Noiseprint image]\n",
    "#   Y -> class of the image\n",
    "# The first generator will produce training data, the second will produce validation data\n",
    "\n",
    "generator_training = Casia2Generator(dataset.as_dataset(split=\"train\"),[\"noiseprint\"],batch_size)\n",
    "generator_validation = Casia2Generator(dataset.as_dataset(split=\"validation\"),[\"noiseprint\"],batch_size)\n",
    "\n",
    "#Train a Resnet Classifier using the Noiseprint data\n",
    "model_noiseprint = BaseClassifier(input_shape_noiseprint,output_classes,\"Noiseprint model\",logs_folder,verbose)\n",
    "history_noiseprint , noiseprint_model_path,noiseprint_checkpoint_path =  model_noiseprint.train_model(generator_training,generator_validation,epochs,loss_function,save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_data(history_noiseprint,(\"accuracy\",\"val_accuracy\"),(\"training  accuracy\",\"validation accuracy\"),\"Rgb model training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}